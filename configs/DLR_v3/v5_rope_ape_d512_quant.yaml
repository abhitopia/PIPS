experiment_config:
  model_config:
    n_dim: 512
    n_head: 8
    n_grid_layer: 2
    n_latent_layer: 2
    n_codes: 128
    codebook_size: 512
    rope_base_height: 10007
    rope_base_width: 5003
    dropout: 0.0
    max_grid_height: 32
    max_grid_width: 32
    n_vocab: 16
    padding_idx: 15
    mask_idx: 14
    pad_weight: 0.1
    gamma: 2.0
    skip_codebook: false
    use_ema: true
    ema_decay: 0.95
    unused_reset_threshold: 0.1
    distance_reset: true
    use_rope: true
    use_ape: true
    return_attn_entropy: false
  batch_size: 64
  beta_commitment: 0.25
  kmeans_init_codebook: true
  kmeans_init_max_datapoints: 2000000
  kmeans_init_batch_size: 100000
  seed: 194360841
  max_steps: 1000000
  gradient_clip_val: 1.0
  accumulate_grad_batches: 1
  mask_schedule_type: cosine
  learning_rate: 0.0001
  lr_min: 1.0e-06
  warmup_steps_lr: 100
  decay_steps_lr: 999900
  weight_decay: 0.0
  beta_attn_entropy: 0.0
  mask_pct_start: 0.0
  max_mask_pct: 0.0
  transition_steps_mask_pct: 50000
  warmup_steps_mask_pct: 0
  train_ds: TRAIN
  val_ds: VAL
  limit_training_samples: null
  permute_train: true
  model_src: v5_rope_ape_d512_quant/best/36000
project_config:
  run_name: v5_rope_ape_d512_quant_v2
  project_name: DLR_v3
  checkpoint_dir: runs
  val_check_interval: 1000
  viz_interval: 1000
